{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db91f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import io\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b6f924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jatin\n",
      "[nltk_data]     Prashant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jatin\n",
      "[nltk_data]     Prashant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Jatin\n",
      "[nltk_data]     Prashant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee5bd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=pd.read_csv('C:\\\\users\\\\Jatin Prashant\\\\Desktop\\\\twittertrain.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49fbf3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b132d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data=pd.read_csv('C:\\\\users\\\\Jatin Prashant\\\\Desktop\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "620f49da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@AmericanAir In car gng to DFW. Pulled over 1hr ago - very icy roads. On-hold with AA since 1hr. Can't reach arpt for AA2450. Wat 2 do?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb51ec5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=training_data[\"text\"]\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d6670be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest=testing_data[\"text\"]\n",
    "xtest=np.array(xtest)\n",
    "xtest=xtest.reshape(len(xtest),1)\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca1be196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10980, 1), (10980, 1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=training_data[\"airline_sentiment\"]\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "x=x.reshape(len(x),1)\n",
    "y=y.reshape(len(y),1)\n",
    "x.shape,y.shape\n",
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "453727df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#off two features\n",
    "\n",
    "train=np.append(x,y,axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37d28b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=xtest\n",
    "test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad52e21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['@',\n",
       "   'SouthwestAir',\n",
       "   'I',\n",
       "   'am',\n",
       "   'scheduled',\n",
       "   'for',\n",
       "   'the',\n",
       "   'morning',\n",
       "   ',',\n",
       "   '2',\n",
       "   'days',\n",
       "   'after',\n",
       "   'the',\n",
       "   'fact',\n",
       "   ',',\n",
       "   'yes',\n",
       "   '..',\n",
       "   'not',\n",
       "   'sure',\n",
       "   'why',\n",
       "   'my',\n",
       "   'evening',\n",
       "   'flight',\n",
       "   'was',\n",
       "   'the',\n",
       "   'only',\n",
       "   'one',\n",
       "   'Cancelled',\n",
       "   'Flightled'],\n",
       "  'negative')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=[]\n",
    "c=0\n",
    "for text,category in train:\n",
    "    c=c+1\n",
    "    documents.append((word_tokenize(text), category))\n",
    "print(\"The End\")\n",
    "documents[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c060d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['[',\n",
       "  '``',\n",
       "  '@',\n",
       "  'AmericanAir',\n",
       "  'In',\n",
       "  'car',\n",
       "  'gng',\n",
       "  'to',\n",
       "  'DFW',\n",
       "  '.',\n",
       "  'Pulled',\n",
       "  'over',\n",
       "  '1hr',\n",
       "  'ago',\n",
       "  '-',\n",
       "  'very',\n",
       "  'icy',\n",
       "  'roads',\n",
       "  '.',\n",
       "  'On-hold',\n",
       "  'with',\n",
       "  'AA',\n",
       "  'since',\n",
       "  '1hr',\n",
       "  '.',\n",
       "  'Ca',\n",
       "  \"n't\",\n",
       "  'reach',\n",
       "  'arpt',\n",
       "  'for',\n",
       "  'AA2450',\n",
       "  '.',\n",
       "  'Wat',\n",
       "  '2',\n",
       "  'do',\n",
       "  '?',\n",
       "  \"''\",\n",
       "  ']'],\n",
       " ['[',\n",
       "  \"'\",\n",
       "  '@',\n",
       "  'AmericanAir',\n",
       "  'after',\n",
       "  'all',\n",
       "  ',',\n",
       "  'the',\n",
       "  'plane',\n",
       "  'didn',\n",
       "  '’',\n",
       "  't',\n",
       "  'land',\n",
       "  'in',\n",
       "  'identical',\n",
       "  'or',\n",
       "  'worse',\n",
       "  ')',\n",
       "  'conditions',\n",
       "  'at',\n",
       "  'GRK',\n",
       "  'according',\n",
       "  'to',\n",
       "  'METARs',\n",
       "  '.',\n",
       "  \"'\",\n",
       "  ']']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "test_documents=[]\n",
    "c=0\n",
    "for text in test:\n",
    "    c=c+1\n",
    "    test_documents.append(word_tokenize(str(text)))\n",
    "print(\"The End\")\n",
    "test_documents[0:2]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642146e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c1ca3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['“',\n",
       "   '@',\n",
       "   'JetBlue',\n",
       "   ':',\n",
       "   '@',\n",
       "   'jannasaurusrex',\n",
       "   'Thanks',\n",
       "   'for',\n",
       "   'the',\n",
       "   'kind',\n",
       "   'words',\n",
       "   ',',\n",
       "   'Janna',\n",
       "   '!',\n",
       "   '#',\n",
       "   'WeAppreciateYou',\n",
       "   '#',\n",
       "   'TrueBlue',\n",
       "   '”',\n",
       "   'and',\n",
       "   'now',\n",
       "   'I',\n",
       "   \"'M\",\n",
       "   'feeling',\n",
       "   'like',\n",
       "   'a',\n",
       "   'boss',\n",
       "   '#',\n",
       "   'jetbluefame'],\n",
       "  'positive'),\n",
       " (['@',\n",
       "   'united',\n",
       "   'Home',\n",
       "   'is',\n",
       "   'Calgary',\n",
       "   'can',\n",
       "   'you',\n",
       "   'get',\n",
       "   'us',\n",
       "   'there',\n",
       "   'without',\n",
       "   'the',\n",
       "   'added',\n",
       "   'expense',\n",
       "   'of',\n",
       "   'accommodations',\n",
       "   'and',\n",
       "   'meals',\n",
       "   '.'],\n",
       "  'neutral')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(documents)\n",
    "documents[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dc8635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b116afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    if tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    if tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e16b664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jatin Prashant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('better', 'RBR')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "\n",
    "from nltk import pos_tag\n",
    "w=\"better\"\n",
    "pos_tag([w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f97c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stops, string punctuation\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "stops= set(stopwords.words(\"english\"))\n",
    "punctuation= list(string.punctuation)\n",
    "stops.update(punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e7bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2021fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words = []\n",
    "    #regex = re.compile('[a-zA-Z0-9_-]+$')\n",
    "    regex = re.compile('[a-zA-Z_-]+$')\n",
    "    for w in words:\n",
    "        if w.lower() not in stops and len(w)>2 and not w.isnumeric() and re.match(regex,w):\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96f13d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[(clean_review(document),category)for document, category in documents]\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents=[clean_review(document) for document in test_documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a09edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_documents= documents \n",
    "testing_documents=test_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d4694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[category for document , category in training_documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining All features in each tuple for Train Data\n",
    "\n",
    "text_documents = [\" \".join(document) for document, category in training_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining All features in each tuple for Test Data\n",
    "\n",
    "test_text_documents = [\" \".join(document) for document in testing_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe968c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(text_documents,categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38cd60dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec=CountVectorizer(max_features=7000)\n",
    "x_train_features = count_vec.fit_transform(text_documents)\n",
    "x_train_features.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37d4447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 7000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile('[a-zA-Z_-]+$')\n",
    "re.match(regex,'jatinprashant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e2c6df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__rwg__',\n",
       " '_austrian',\n",
       " '_defcon_',\n",
       " '_emmaclifford',\n",
       " '_exact_',\n",
       " '_justdippin_',\n",
       " 'a_life_story_',\n",
       " 'aa',\n",
       " 'aaaand',\n",
       " 'aadvantage',\n",
       " 'aafail',\n",
       " 'aal',\n",
       " 'aaron',\n",
       " 'aarp',\n",
       " 'abandon',\n",
       " 'abandonment',\n",
       " 'abassinet',\n",
       " 'abbreve',\n",
       " 'abc',\n",
       " 'abcnetwork',\n",
       " 'abcnews',\n",
       " 'abduct',\n",
       " 'abi',\n",
       " 'abigailedge',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'aboout',\n",
       " 'abounds',\n",
       " 'abq',\n",
       " 'abroad',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorber',\n",
       " 'absoulutely',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abysmal',\n",
       " 'acc',\n",
       " 'accelerate',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'accomidating',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accrue',\n",
       " 'acct',\n",
       " 'accts',\n",
       " 'accumulation',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuratetraveltimes',\n",
       " 'accuse',\n",
       " 'achieve',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acnewsguy',\n",
       " 'acosta',\n",
       " 'acoustic',\n",
       " 'acpt',\n",
       " 'acquire',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actingoutmgmnt',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'active_aly',\n",
       " 'actively',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'acu',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adam',\n",
       " 'adam_karren',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addair',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additonal',\n",
       " 'addr',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'addtl',\n",
       " 'adjacent',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'admiral',\n",
       " 'admirals',\n",
       " 'admiralsclub',\n",
       " 'admit',\n",
       " 'adolfo',\n",
       " 'adopt',\n",
       " 'adopting',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adv',\n",
       " 'advan',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advertise',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advis',\n",
       " 'advise',\n",
       " 'advisory',\n",
       " 'advsry',\n",
       " 'aerocivilcol',\n",
       " 'aerojobmarket',\n",
       " 'aeroport',\n",
       " 'aex',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affiliate',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afiliates',\n",
       " 'aflame',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'afterall',\n",
       " 'afternoon',\n",
       " 'aftr',\n",
       " 'again',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aggiemensgolf',\n",
       " 'aggravate',\n",
       " 'aggravation',\n",
       " 'aggressive',\n",
       " 'agnt',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'agt',\n",
       " 'agts',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhhh',\n",
       " 'ahold',\n",
       " 'ahoy',\n",
       " 'ail',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'airbus',\n",
       " 'airbusintheus',\n",
       " 'aircanada',\n",
       " 'aircargo',\n",
       " 'aircraft',\n",
       " 'aires',\n",
       " 'airfare',\n",
       " 'airfarewatchdog',\n",
       " 'airline',\n",
       " 'airlinegeeks',\n",
       " 'airlineguys',\n",
       " 'airlinequality',\n",
       " 'airliner',\n",
       " 'airlines',\n",
       " 'airlinesecurity',\n",
       " 'airnzusa',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airportcardio',\n",
       " 'airpt',\n",
       " 'airside',\n",
       " 'airstairs',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'ais',\n",
       " 'aisle',\n",
       " 'aka',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alamo',\n",
       " 'alan_bledsoe',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'alaskaair',\n",
       " 'alavera',\n",
       " 'alb',\n",
       " 'albany',\n",
       " 'albanyairport',\n",
       " 'albeit',\n",
       " 'albertbreer',\n",
       " 'album',\n",
       " 'albuquer',\n",
       " 'albuquerque',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alfamilyoffour',\n",
       " 'ali',\n",
       " 'alicia',\n",
       " 'align',\n",
       " 'alison',\n",
       " 'alist',\n",
       " 'alittlebetter',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allan',\n",
       " 'allegiantair',\n",
       " 'allegianttravel',\n",
       " 'allende',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'allgood',\n",
       " 'alliance',\n",
       " 'allow',\n",
       " 'allowabl',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allready',\n",
       " 'allyoucanjetpass',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alreadyrebookedonce',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'also',\n",
       " 'alsonodrinkcartcomingaround',\n",
       " 'alstdi',\n",
       " 'alt',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'altonbrownlive',\n",
       " 'always',\n",
       " 'alwaysdelayed',\n",
       " 'alwayshappensthere',\n",
       " 'alwayslate',\n",
       " 'alynewton',\n",
       " 'am',\n",
       " 'amagrino',\n",
       " 'amarillo',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazings',\n",
       " 'amazon',\n",
       " 'ambivalence',\n",
       " 'amen',\n",
       " 'amenity',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanairbr',\n",
       " 'americanairlines',\n",
       " 'americanairlnes',\n",
       " 'americanairsucks',\n",
       " 'americanforlife',\n",
       " 'americanone',\n",
       " 'americant',\n",
       " 'americanview',\n",
       " 'amex',\n",
       " 'amin_aur',\n",
       " 'amirite',\n",
       " 'amm',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'ams',\n",
       " 'amsterdam',\n",
       " 'amt',\n",
       " 'amy',\n",
       " 'amybruni',\n",
       " 'amypoehler',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'analystdoc',\n",
       " 'analysts',\n",
       " 'analytics',\n",
       " 'anamarketers',\n",
       " 'anaphylaxis',\n",
       " 'anarchy',\n",
       " 'anchorage',\n",
       " 'andchexmix',\n",
       " 'anderson',\n",
       " 'andrew',\n",
       " 'andrew_wasila',\n",
       " 'andrewbiga',\n",
       " 'andrewfallis',\n",
       " 'andrews',\n",
       " 'android',\n",
       " 'andthewinneris',\n",
       " 'andyellwood',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angle',\n",
       " 'angriest',\n",
       " 'angry',\n",
       " 'angryandsober',\n",
       " 'angrybird',\n",
       " 'angrycustomer',\n",
       " 'angrytraveler',\n",
       " 'angst',\n",
       " 'anhour',\n",
       " 'animal',\n",
       " 'anku',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annebevi',\n",
       " 'annettenaif',\n",
       " 'anni',\n",
       " 'anniversary',\n",
       " 'annnndddd',\n",
       " 'annnnddddd',\n",
       " 'annnnnd',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annricord',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'answerphone',\n",
       " 'answerthephone',\n",
       " 'answerthis',\n",
       " 'ant_kneee',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipation',\n",
       " 'antigua',\n",
       " 'antitrust',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhelp',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyonethere',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apathetic',\n",
       " 'apathy',\n",
       " 'apeared',\n",
       " 'apnea',\n",
       " 'apollochplayers',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologizes',\n",
       " 'apology',\n",
       " 'apostrophe',\n",
       " 'apostrophefail',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'applaud',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'applepay',\n",
       " 'appleton',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appoint',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'appropriation',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'apx',\n",
       " 'aquadilla',\n",
       " 'arab',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'ardent',\n",
       " 'are',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'areyounew',\n",
       " 'argentina',\n",
       " 'argg',\n",
       " 'argh',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'arm',\n",
       " 'arminrosen',\n",
       " 'armrest',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artisanal',\n",
       " 'aruba',\n",
       " 'aruba_airport',\n",
       " 'aruna',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ase',\n",
       " 'ash',\n",
       " 'asha',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'ashleykatherton',\n",
       " 'asia',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'askpaypal',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspen',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'assult',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'astound',\n",
       " 'astounds',\n",
       " 'at',\n",
       " 'atc',\n",
       " 'atct',\n",
       " 'ath',\n",
       " 'athlete',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atrocious',\n",
       " 'att',\n",
       " 'attach',\n",
       " 'attain',\n",
       " 'attdt',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attendants',\n",
       " 'attendee',\n",
       " 'attendents',\n",
       " 'attention',\n",
       " 'attentiveness',\n",
       " 'attitude',\n",
       " 'attitudeissues',\n",
       " 'attndt',\n",
       " 'atwonline',\n",
       " 'auciello',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'audience',\n",
       " 'audition',\n",
       " 'auditorium',\n",
       " 'auf',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'auh',\n",
       " 'aunt',\n",
       " 'aunty',\n",
       " 'aus',\n",
       " 'austic',\n",
       " 'austin',\n",
       " 'austinairport',\n",
       " 'australia',\n",
       " 'austrian',\n",
       " 'author',\n",
       " 'authoritative',\n",
       " 'authority',\n",
       " 'authorize',\n",
       " 'auto',\n",
       " 'automate',\n",
       " 'automatically',\n",
       " 'automobile',\n",
       " 'autoresponse',\n",
       " 'av_duffy',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avert',\n",
       " 'avgeek',\n",
       " 'aviation',\n",
       " 'avios',\n",
       " 'avis',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avon',\n",
       " 'avp',\n",
       " 'await',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'aweful',\n",
       " 'awesome',\n",
       " 'awesomeee',\n",
       " 'awesomeness',\n",
       " 'awful',\n",
       " 'awfulness',\n",
       " 'awheelchair',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awrd',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwweesssooomee',\n",
       " 'ayyy',\n",
       " 'ba_usa',\n",
       " 'baby',\n",
       " 'bach',\n",
       " 'bachelorpartymishap',\n",
       " 'back',\n",
       " 'backing',\n",
       " 'backlog',\n",
       " 'backpack',\n",
       " 'backroads',\n",
       " 'backup',\n",
       " 'backwards',\n",
       " 'bad',\n",
       " 'badbadbad',\n",
       " 'badbusiness',\n",
       " 'badbussiness',\n",
       " 'badcustomerservice',\n",
       " 'badcustomersrvice',\n",
       " 'bademployeeproblem',\n",
       " 'badge',\n",
       " 'badges',\n",
       " 'badly',\n",
       " 'badmgmt',\n",
       " 'badpolicy',\n",
       " 'badservice',\n",
       " 'badwebsite',\n",
       " 'bae',\n",
       " 'baejet',\n",
       " 'bafore',\n",
       " 'baftz',\n",
       " 'bag',\n",
       " 'bagage',\n",
       " 'bagawim',\n",
       " 'baggage',\n",
       " 'baggagelost',\n",
       " 'bags',\n",
       " 'bahamas',\n",
       " 'bail',\n",
       " 'bailey',\n",
       " 'bait',\n",
       " 'baitandswitch',\n",
       " 'bake',\n",
       " 'baking',\n",
       " 'balance',\n",
       " 'baldordash',\n",
       " 'baldwin',\n",
       " 'ball',\n",
       " 'ballin',\n",
       " 'balls',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bandie',\n",
       " 'bandwidth',\n",
       " 'bangkok',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'bar',\n",
       " 'barbados',\n",
       " 'barbara',\n",
       " 'barclay',\n",
       " 'barclaycardus',\n",
       " 'barclays',\n",
       " 'barcodes',\n",
       " 'barely',\n",
       " 'barking',\n",
       " 'barklays',\n",
       " 'barnum',\n",
       " 'barrel',\n",
       " 'barrettkarabis',\n",
       " 'barrier',\n",
       " 'bars',\n",
       " 'barzegar',\n",
       " 'base',\n",
       " 'bashing',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battery',\n",
       " 'battierccipuppy',\n",
       " 'batting',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'battling',\n",
       " 'bay',\n",
       " 'bbb_media',\n",
       " 'bbbne_sd_ks_ia',\n",
       " 'bcn',\n",
       " 'bcuz',\n",
       " 'bday',\n",
       " 'bdindallas',\n",
       " 'bdl',\n",
       " 'bdng',\n",
       " 'bdsm',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beamske',\n",
       " 'bean',\n",
       " 'beanie',\n",
       " 'beantownmatty',\n",
       " 'bear',\n",
       " 'bearable',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beatriz',\n",
       " 'beats',\n",
       " 'beatsmusic',\n",
       " 'beatstheothers',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'bed',\n",
       " 'bedofroses',\n",
       " 'beefjerky',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'befor',\n",
       " 'beg',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'begrudgingly',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behaves',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'beingsuckontarmacsucks',\n",
       " 'belabor',\n",
       " 'belfast',\n",
       " 'belfastairport',\n",
       " 'belief',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'belize',\n",
       " 'bellagio',\n",
       " 'belligerent',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'benadryl',\n",
       " 'bench',\n",
       " 'bene',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benjaminokeefe',\n",
       " 'bensonhenderson',\n",
       " 'beought',\n",
       " 'bereavement',\n",
       " 'bergstrom',\n",
       " 'berlin',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bestairline',\n",
       " 'bestairlineever',\n",
       " 'bestemployees',\n",
       " 'bestflightever',\n",
       " 'besty',\n",
       " 'bet',\n",
       " 'betsy',\n",
       " 'better',\n",
       " 'beverage',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bff',\n",
       " 'bgm',\n",
       " 'bgr',\n",
       " 'bhm',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'billing',\n",
       " 'billion',\n",
       " 'bin',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'birmingham',\n",
       " 'birth',\n",
       " 'birthdate',\n",
       " 'birthday',\n",
       " 'biscuit',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitchy',\n",
       " 'bite',\n",
       " 'bitty',\n",
       " 'biz',\n",
       " 'bizarre',\n",
       " 'biztravel',\n",
       " 'bked',\n",
       " 'bkk',\n",
       " 'black',\n",
       " 'blackhistorymonth',\n",
       " 'blacklist',\n",
       " 'blacklivesmatter',\n",
       " 'blackmailed',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blameshiftoverload',\n",
       " 'blanc',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'blasting',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'blatimore',\n",
       " 'blegh',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blindside',\n",
       " 'bliss',\n",
       " 'blizzard',\n",
       " 'bloat',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'bloodymary',\n",
       " 'bloombergradio',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bluecarpet',\n",
       " 'bluemanity',\n",
       " 'bluetiful',\n",
       " 'blushing',\n",
       " 'bmi',\n",
       " 'bna',\n",
       " 'bnasnow',\n",
       " 'bng',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boarding',\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'bobbi',\n",
       " 'bobwesson',\n",
       " 'body',\n",
       " 'boeing',\n",
       " 'boeingairplanes',\n",
       " 'bogota',\n",
       " 'bohol',\n",
       " 'boil',\n",
       " 'boise',\n",
       " 'bold',\n",
       " 'boldflavors',\n",
       " 'bom',\n",
       " 'bonnie',\n",
       " 'bonsinthesky',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boofin',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'booklet',\n",
       " 'bookofnegroes',\n",
       " 'bool',\n",
       " 'boom',\n",
       " 'boooo',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'booze',\n",
       " 'bop',\n",
       " 'bora',\n",
       " 'border',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bostonlogan',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bougth',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bqn',\n",
       " 'brag',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brandloveaffair',\n",
       " 'brandmance',\n",
       " 'brandssayingbae',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breath',\n",
       " 'bretharold',\n",
       " 'brian',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'british_airways',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brokenpromises',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'browser',\n",
       " 'bruh',\n",
       " 'brushing',\n",
       " 'brutal',\n",
       " 'btr',\n",
       " 'bttr',\n",
       " 'btv',\n",
       " 'btw',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buenos',\n",
       " 'buf',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bumped',\n",
       " 'bumper',\n",
       " 'bumping',\n",
       " 'bunch',\n",
       " 'burbank',\n",
       " 'burning',\n",
       " 'burningman',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'busiest',\n",
       " 'business',\n",
       " 'businessfirst',\n",
       " 'businesstravel',\n",
       " 'bussey',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butnot',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyback',\n",
       " 'buyer',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'bwahahaha',\n",
       " 'bwi',\n",
       " 'bwi_airport',\n",
       " 'bwood',\n",
       " 'bye',\n",
       " 'byebyejetblue',\n",
       " 'byod',\n",
       " 'bze',\n",
       " 'c_istudios',\n",
       " 'cab',\n",
       " 'cabcelled',\n",
       " 'cabin',\n",
       " 'cabine',\n",
       " 'cable',\n",
       " 'cabo',\n",
       " 'cac',\n",
       " 'cache',\n",
       " 'cae',\n",
       " 'caexhibitions',\n",
       " 'cafe',\n",
       " 'caffeine',\n",
       " 'cakairport',\n",
       " 'cake',\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3124340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x7000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 31548 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_features = count_vec.transform(test_text_documents)\n",
    "x_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c21be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=x_train_features\n",
    "ytrain=categories\n",
    "xtest=x_test_features\n",
    "#ytest=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27205fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210dc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=0.2,kernel='linear')\n",
    "svc.fit(xtrain, ytrain)\n",
    "#svc.score(xtest, ytest)\n",
    "svc=svc.predict(xtest)\n",
    "svc=np.array(svc)\n",
    "np.savetxt(\"svc(nlp2).csv\",svc, fmt='%s',encoding=None)\n",
    "files.download(\"svc(nlp2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf48f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAUSSIAN NAIVE BAYES SCORE TEST\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5d4c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTINOMIAL NAIVE BAYES SCORE TEST\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0.83)\n",
    "clf.fit(xtrain.toarray(), ytrain)\n",
    "\n",
    "mnb=clf.predict(xtest)\n",
    "mnb=np.array(mnb)\n",
    "\n",
    "#np.savetxt(\"mnb(nlp2).csv\",mnb, fmt='%s',encoding=None)\n",
    "#files.download(\"mnb(nlp2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8adb2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classfier = NaiveBayesClassifier.train(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive=classfier.classify_many(ytest)\n",
    "#naive=np.array(naive)\n",
    "#nltk.classify.accuracy(classfier, ytest)\n",
    "#os.chdir(\"C:\\\\Users\\\\hp\\\\Desktop\")\n",
    "#np.savetxt(\"naive1.csv\",naive, fmt='%s',encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb40d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
